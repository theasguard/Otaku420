import urllib.parse
    def _get_episode_sources(self, show, anilist_id, episode, status, rescrape):
        if rescrape:
            return self._get_episode_sources_pack(show, anilist_id, episode)
        
        try:
            cached_sources, zfill_int = database.getTorrentList(anilist_id)
            if cached_sources:
                return self._process_cached_sources(cached_sources, episode.zfill(zfill_int))
        except ValueError:
            pass
        
        query = f'{show} "- {episode.zfill(2)}"'
        season = database.get_season_list(anilist_id)
        if season:
            season = str(season['season']).zfill(2)
            query += f'|"S{season}E{episode.zfill(2)}"'
        
        url = f'{self._BASE_URL}?f=0&c=1_0&q={urllib.parse.quote_plus(query)}&s=downloads&o=desc'
        
        if status == 'FINISHED':
            query = f'{show} "Batch"|"Complete Series"'
            episodes = pickle.loads(database.get_show(anilist_id)['kodi_meta'])['episodes']
            if episodes:
                query += f'|"01-{episodes}"|"01~{episodes}"|"01 - {episodes}"|"01 ~ {episodes}"'
        
            if season:
                query += f'|"S{season}"|"Season {season}"'
                query += f'|"S{season}E{episode.zfill(2)}"'
        
            query += f'|"- {episode.zfill(2)}"'
            url = f'{self._BASE_URL}?f=0&c=1_0&q={urllib.parse.quote_plus(query)}&s=seeders&&o=desc'
        
        return self._process_nyaa_episodes(url, episode.zfill(2), season)
