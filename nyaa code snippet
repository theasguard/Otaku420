import urllib.parse
    def _get_episode_sources(self, show, anilist_id, episode, status, rescrape):
        if rescrape:
            return self._get_episode_sources_pack(show, anilist_id, episode)
        
        try:
            cached_sources, zfill_int = database.getTorrentList(anilist_id)
            if cached_sources:
                return self._process_cached_sources(cached_sources, episode.zfill(zfill_int))
        except ValueError:
            pass
        
        # Construct the base query with the show and episode information
        query = f'{show} "- {episode.zfill(2)}"'
        
        # Retrieve season information
        season = database.get_season_list(anilist_id)
        if season:
            season = str(season['season']).zfill(2)
            query += f'|"S{season}E{episode.zfill(2)}"'
        
        # Construct the URL with the base query
        url = f'{self._BASE_URL}?f=0&c=1_0&q={urllib.parse.quote_plus(query)}&s=downloads&o=desc'
        
        # Check if the status is 'FINISHED'
        if status == 'FINISHED':
            # Construct additional queries for 'Batch' and 'Complete Series' if available
            query = f'{show} "Batch"|"Complete Series"'
            episodes = pickle.loads(database.get_show(anilist_id)['kodi_meta'])['episodes']
            if episodes:
                query += f'|"01-{episodes}"|"01~{episodes}"|"01 - {episodes}"|"01 ~ {episodes}"'
        
            # Append season information if available
            if season:
                query += f'|"S{season}"|"Season {season}"'
                query += f'|"S{season}E{episode.zfill(2)}"'
        
            # Append episode information
            query += f'|"- {episode.zfill(2)}"'
            # Construct the URL with the updated query for 'FINISHED' status
            url = f'{self._BASE_URL}?f=0&c=1_0&q={urllib.parse.quote_plus(query)}&s=seeders&o=desc'
        
        # Process the nyaa.si episodes using the constructed URL
        return self._process_nyaa_episodes(url, episode.zfill(2), season)


    def _get_episode_sources_pack(self, show, anilist_id, episode):
        # Construct the base query with "Batch" and "Complete Series"
        query = f'{show} "Batch"|"Complete Series"'
    
        # Retrieve episode information from Kodi metadata
        episodes = pickle.loads(database.get_show(anilist_id)['kodi_meta'])['episodes']
        if episodes:
            # Append queries for individual episodes if available
            query += f'|"01-{episodes}"|"01~{episodes}"|"01 - {episodes}"|"01 ~ {episodes}"'
    
        # Retrieve season information
        season = database.get_season_list(anilist_id)
        if season:
            # Append queries for seasons if available
            season = season['season']
            query += f'|"S{season}"|"Season {season}"'
    
        # Construct the URL with the base query
        url = f'{self._BASE_URL}?f=0&c=1_2&q={urllib.parse.quote_plus(query)}&s=seeders&o=desc'
    
        # Process the nyaa.si backup with the constructed URL
        return self._process_nyaa_backup(url, anilist_id, 2, episode.zfill(2), True)
